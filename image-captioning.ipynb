{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_colwidth', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T16:50:27.773294Z","iopub.execute_input":"2024-10-29T16:50:27.773725Z","iopub.status.idle":"2024-10-29T16:50:27.778928Z","shell.execute_reply.started":"2024-10-29T16:50:27.773685Z","shell.execute_reply":"2024-10-29T16:50:27.777669Z"},"trusted":true},"outputs":[],"execution_count":77},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\", sep=\",\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:50:27.917997Z","iopub.execute_input":"2024-10-29T16:50:27.918423Z","iopub.status.idle":"2024-10-29T16:50:27.995259Z","shell.execute_reply.started":"2024-10-29T16:50:27.918383Z","shell.execute_reply":"2024-10-29T16:50:27.994285Z"},"trusted":true},"outputs":[],"execution_count":78},{"cell_type":"code","source":"df.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:50:28.088898Z","iopub.execute_input":"2024-10-29T16:50:28.089350Z","iopub.status.idle":"2024-10-29T16:50:28.100253Z","shell.execute_reply.started":"2024-10-29T16:50:28.089294Z","shell.execute_reply":"2024-10-29T16:50:28.099127Z"},"trusted":true},"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"                       image  \\\n0  1000268201_693b08cb0e.jpg   \n1  1000268201_693b08cb0e.jpg   \n2  1000268201_693b08cb0e.jpg   \n\n                                                                    caption  \n0  A child in a pink dress is climbing up a set of stairs in an entry way .  \n1                                     A girl going into a wooden building .  \n2                          A little girl climbing into a wooden playhouse .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set of stairs in an entry way .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":79},{"cell_type":"code","source":"def process_caption(caption):\n    words = caption.split()\n    return ['<sos>'] + words + ['<eos>']\n\ndef remove_single_char_word(word_list):\n    lst = []\n    for word in word_list:\n        if len(word)>1:\n            lst.append(word)\n\n    return lst\n\ndf['cleaned_caption'] = df['caption'].apply(lambda caption : ['<start>'] + [word.lower() if word.isalpha() else '' for word in caption.split(\" \")] + ['<end>'])\ndf['cleaned_caption']  = df['cleaned_caption'].apply(lambda x : remove_single_char_word(x))\ndf['seq_len'] = df['cleaned_caption'].apply(lambda x : len(x))\ndf['seq_len'].max()\ndf['cleaned_caption'].head(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:50:28.317817Z","iopub.execute_input":"2024-10-29T16:50:28.318768Z","iopub.status.idle":"2024-10-29T16:50:28.791472Z","shell.execute_reply.started":"2024-10-29T16:50:28.318725Z","shell.execute_reply":"2024-10-29T16:50:28.790348Z"},"trusted":true},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"0    [<start>, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, <end>]\n1                                              [<start>, girl, going, into, wooden, building, <end>]\n2                                  [<start>, little, girl, climbing, into, wooden, playhouse, <end>]\nName: cleaned_caption, dtype: object"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"def pad_words(words, target_length=33, pad_token='<pad>'):\n    length = len(words)\n    if length < target_length:\n        return words + [pad_token] * (target_length - length)\n    else:\n        return words[:target_length]\n\ndf['cleaned_caption'] = df['cleaned_caption'].apply(pad_words)\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T16:50:25.071288Z","iopub.execute_input":"2024-10-29T16:50:25.072192Z","iopub.status.idle":"2024-10-29T16:50:25.165230Z","shell.execute_reply.started":"2024-10-29T16:50:25.072144Z","shell.execute_reply":"2024-10-29T16:50:25.164220Z"},"trusted":true},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                       image  \\\n0  1000268201_693b08cb0e.jpg   \n1  1000268201_693b08cb0e.jpg   \n2  1000268201_693b08cb0e.jpg   \n\n                                                                    caption  \\\n0  A child in a pink dress is climbing up a set of stairs in an entry way .   \n1                                     A girl going into a wooden building .   \n2                          A little girl climbing into a wooden playhouse .   \n\n                                                                                                                                                                                                                                    cleaned_caption  \\\n0                            [<start>, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]   \n1       [<start>, girl, going, into, wooden, building, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]   \n2  [<start>, little, girl, climbing, into, wooden, playhouse, <end>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]   \n\n   seq_len  \n0       16  \n1        7  \n2        8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n      <th>cleaned_caption</th>\n      <th>seq_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set of stairs in an entry way .</td>\n      <td>[&lt;start&gt;, child, in, pink, dress, is, climbing, up, set, of, stairs, in, an, entry, way, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n      <td>[&lt;start&gt;, girl, going, into, wooden, building, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n      <td>[&lt;start&gt;, little, girl, climbing, into, wooden, playhouse, &lt;end&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"csv_file_path = \"/kaggle/input/flickr8k/captions.txt\"\nimages_path = \"/kaggle/input/flickr8k/Images/\"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\nclass Flickr8K(Dataset):\n    def __init__(self, csv_file, images_path):\n        self.df = pd.read_csv(path, sep=\",\")\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        img_path = images_path + self.df.iloc[idx, 0]\n        image = Image.open(img_path).convert(\"RGB\")\n        target = self.df.iloc[idx, 1]  \n        return image, target\n\ndataset = Flickr8K(csv_file_path, images_path)\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T09:44:46.687464Z","iopub.execute_input":"2024-10-27T09:44:46.688148Z","iopub.status.idle":"2024-10-27T09:44:46.710053Z","shell.execute_reply.started":"2024-10-27T09:44:46.688076Z","shell.execute_reply":"2024-10-27T09:44:46.708144Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}