{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/prasannakasar/image-captioning?scriptVersionId=220256340\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"aa01327c","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-01T12:47:17.934284Z","iopub.status.busy":"2025-02-01T12:47:17.93358Z","iopub.status.idle":"2025-02-01T12:47:18.651545Z","shell.execute_reply":"2025-02-01T12:47:18.650782Z"},"papermill":{"duration":0.72832,"end_time":"2025-02-01T12:47:18.653573","exception":false,"start_time":"2025-02-01T12:47:17.925253","status":"completed"},"tags":[]},"outputs":[],"source":["import pandas as pd\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"code","execution_count":2,"id":"81c044e1","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:18.668598Z","iopub.status.busy":"2025-02-01T12:47:18.668173Z","iopub.status.idle":"2025-02-01T12:47:18.672443Z","shell.execute_reply":"2025-02-01T12:47:18.671603Z"},"papermill":{"duration":0.013085,"end_time":"2025-02-01T12:47:18.67415","exception":false,"start_time":"2025-02-01T12:47:18.661065","status":"completed"},"tags":[]},"outputs":[],"source":["# df = pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\", sep=\",\")"]},{"cell_type":"code","execution_count":3,"id":"76cdf0e8","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:18.686831Z","iopub.status.busy":"2025-02-01T12:47:18.686371Z","iopub.status.idle":"2025-02-01T12:47:18.6899Z","shell.execute_reply":"2025-02-01T12:47:18.689203Z"},"papermill":{"duration":0.011773,"end_time":"2025-02-01T12:47:18.691622","exception":false,"start_time":"2025-02-01T12:47:18.679849","status":"completed"},"tags":[]},"outputs":[],"source":["BASE_PATH = '../input/coco-2017-dataset/coco2017'"]},{"cell_type":"code","execution_count":4,"id":"9978f886","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:18.704238Z","iopub.status.busy":"2025-02-01T12:47:18.703916Z","iopub.status.idle":"2025-02-01T12:47:22.206906Z","shell.execute_reply":"2025-02-01T12:47:22.205876Z"},"papermill":{"duration":3.511424,"end_time":"2025-02-01T12:47:22.208754","exception":false,"start_time":"2025-02-01T12:47:18.69733","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>caption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg</td>\n","      <td>A bicycle replica with a clock as the front wheel.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg</td>\n","      <td>A room with blue walls and a white sink and door.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg</td>\n","      <td>A car that seems to be parked illegally behind a legally parked car</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000106140.jpg</td>\n","      <td>A large passenger airplane flying through the air.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000106140.jpg</td>\n","      <td>There is a GOL plane taking off in a partly cloudy sky.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            image  \\\n","0  ../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg   \n","1  ../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg   \n","2  ../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg   \n","3  ../input/coco-2017-dataset/coco2017/train2017/000000106140.jpg   \n","4  ../input/coco-2017-dataset/coco2017/train2017/000000106140.jpg   \n","\n","                                                               caption  \n","0                   A bicycle replica with a clock as the front wheel.  \n","1                    A room with blue walls and a white sink and door.  \n","2  A car that seems to be parked illegally behind a legally parked car  \n","3                   A large passenger airplane flying through the air.  \n","4              There is a GOL plane taking off in a partly cloudy sky.  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","\n","with open(f'{BASE_PATH}/annotations/captions_train2017.json', 'r') as f:\n","    data = json.load(f)\n","    data = data['annotations']\n","\n","img_cap_pairs = []\n","\n","for sample in data:\n","    img_name = '%012d.jpg' % sample['image_id']\n","    img_cap_pairs.append([img_name, sample['caption']])\n","\n","df = pd.DataFrame(img_cap_pairs, columns=['image', 'caption'])\n","df['image'] = df['image'].apply(\n","    lambda x: f'{BASE_PATH}/train2017/{x}'\n",")\n","df = df.reset_index(drop=True)\n","df.head()"]},{"cell_type":"code","execution_count":5,"id":"8a12be01","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:22.22296Z","iopub.status.busy":"2025-02-01T12:47:22.222643Z","iopub.status.idle":"2025-02-01T12:47:22.227901Z","shell.execute_reply":"2025-02-01T12:47:22.227061Z"},"papermill":{"duration":0.014091,"end_time":"2025-02-01T12:47:22.229691","exception":false,"start_time":"2025-02-01T12:47:22.2156","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["591753"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(df)"]},{"cell_type":"code","execution_count":6,"id":"00342715","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:22.243753Z","iopub.status.busy":"2025-02-01T12:47:22.243209Z","iopub.status.idle":"2025-02-01T12:47:26.641971Z","shell.execute_reply":"2025-02-01T12:47:26.64088Z"},"papermill":{"duration":4.408274,"end_time":"2025-02-01T12:47:26.644186","exception":false,"start_time":"2025-02-01T12:47:22.235912","status":"completed"},"tags":[]},"outputs":[],"source":["import re\n","\n","df['cleaned_caption'] = df['caption'].apply(lambda caption: re.sub(r\"[^a-zA-Z0-9 ]\", \"\", caption))  # Remove punctuation\n","df['cleaned_caption'] = df['cleaned_caption'].apply(lambda caption: caption.lower().split())  # Convert to lowercase and split\n","df['cleaned_caption'] = df['cleaned_caption'].apply(lambda lis: ['<start>'] + [word for word in lis if word not in {\"a\", \"an\", \"the\"}] + ['<end>'])  # Remove stop words and add tokens\n"]},{"cell_type":"code","execution_count":7,"id":"329277b1","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:26.658314Z","iopub.status.busy":"2025-02-01T12:47:26.657578Z","iopub.status.idle":"2025-02-01T12:47:26.6671Z","shell.execute_reply":"2025-02-01T12:47:26.666244Z"},"papermill":{"duration":0.018587,"end_time":"2025-02-01T12:47:26.668905","exception":false,"start_time":"2025-02-01T12:47:26.650318","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>caption</th>\n","      <th>cleaned_caption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg</td>\n","      <td>A bicycle replica with a clock as the front wheel.</td>\n","      <td>[&lt;start&gt;, bicycle, replica, with, clock, as, front, wheel, &lt;end&gt;]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg</td>\n","      <td>A room with blue walls and a white sink and door.</td>\n","      <td>[&lt;start&gt;, room, with, blue, walls, and, white, sink, and, door, &lt;end&gt;]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg</td>\n","      <td>A car that seems to be parked illegally behind a legally parked car</td>\n","      <td>[&lt;start&gt;, car, that, seems, to, be, parked, illegally, behind, legally, parked, car, &lt;end&gt;]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            image  \\\n","0  ../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg   \n","1  ../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg   \n","2  ../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg   \n","\n","                                                               caption  \\\n","0                   A bicycle replica with a clock as the front wheel.   \n","1                    A room with blue walls and a white sink and door.   \n","2  A car that seems to be parked illegally behind a legally parked car   \n","\n","                                                                               cleaned_caption  \n","0                            [<start>, bicycle, replica, with, clock, as, front, wheel, <end>]  \n","1                       [<start>, room, with, blue, walls, and, white, sink, and, door, <end>]  \n","2  [<start>, car, that, seems, to, be, parked, illegally, behind, legally, parked, car, <end>]  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head(3)\n"]},{"cell_type":"code","execution_count":8,"id":"ff89dd21","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:26.683257Z","iopub.status.busy":"2025-02-01T12:47:26.682917Z","iopub.status.idle":"2025-02-01T12:47:26.873234Z","shell.execute_reply":"2025-02-01T12:47:26.872373Z"},"papermill":{"duration":0.199513,"end_time":"2025-02-01T12:47:26.875068","exception":false,"start_time":"2025-02-01T12:47:26.675555","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["48"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['seq_len'] = df['cleaned_caption'].apply(lambda x : len(x))\n","max_len = df['seq_len'].max()\n","max_len"]},{"cell_type":"code","execution_count":9,"id":"0eecc5df","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:26.8896Z","iopub.status.busy":"2025-02-01T12:47:26.889321Z","iopub.status.idle":"2025-02-01T12:47:27.042106Z","shell.execute_reply":"2025-02-01T12:47:27.041223Z"},"papermill":{"duration":0.162404,"end_time":"2025-02-01T12:47:27.044053","exception":false,"start_time":"2025-02-01T12:47:26.881649","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["495542"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df['cleaned_caption'].apply(len).idxmax()"]},{"cell_type":"code","execution_count":10,"id":"365574d8","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:27.05994Z","iopub.status.busy":"2025-02-01T12:47:27.059368Z","iopub.status.idle":"2025-02-01T12:47:27.063348Z","shell.execute_reply":"2025-02-01T12:47:27.062624Z"},"papermill":{"duration":0.0136,"end_time":"2025-02-01T12:47:27.065033","exception":false,"start_time":"2025-02-01T12:47:27.051433","status":"completed"},"tags":[]},"outputs":[],"source":["# df['cleaned_caption'] = df['cleaned_caption'].apply(lambda lis : lis + ['<pad>'] * (max_len - len(lis)))"]},{"cell_type":"code","execution_count":11,"id":"f5fb72af","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:27.079424Z","iopub.status.busy":"2025-02-01T12:47:27.078775Z","iopub.status.idle":"2025-02-01T12:47:27.088637Z","shell.execute_reply":"2025-02-01T12:47:27.087788Z"},"papermill":{"duration":0.018957,"end_time":"2025-02-01T12:47:27.090509","exception":false,"start_time":"2025-02-01T12:47:27.071552","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>caption</th>\n","      <th>cleaned_caption</th>\n","      <th>seq_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg</td>\n","      <td>A bicycle replica with a clock as the front wheel.</td>\n","      <td>[&lt;start&gt;, bicycle, replica, with, clock, as, front, wheel, &lt;end&gt;]</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg</td>\n","      <td>A room with blue walls and a white sink and door.</td>\n","      <td>[&lt;start&gt;, room, with, blue, walls, and, white, sink, and, door, &lt;end&gt;]</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg</td>\n","      <td>A car that seems to be parked illegally behind a legally parked car</td>\n","      <td>[&lt;start&gt;, car, that, seems, to, be, parked, illegally, behind, legally, parked, car, &lt;end&gt;]</td>\n","      <td>13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            image  \\\n","0  ../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg   \n","1  ../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg   \n","2  ../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg   \n","\n","                                                               caption  \\\n","0                   A bicycle replica with a clock as the front wheel.   \n","1                    A room with blue walls and a white sink and door.   \n","2  A car that seems to be parked illegally behind a legally parked car   \n","\n","                                                                               cleaned_caption  \\\n","0                            [<start>, bicycle, replica, with, clock, as, front, wheel, <end>]   \n","1                       [<start>, room, with, blue, walls, and, white, sink, and, door, <end>]   \n","2  [<start>, car, that, seems, to, be, parked, illegally, behind, legally, parked, car, <end>]   \n","\n","   seq_len  \n","0        9  \n","1       11  \n","2       13  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.head(3)"]},{"cell_type":"code","execution_count":12,"id":"ff25a8fd","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:27.10621Z","iopub.status.busy":"2025-02-01T12:47:27.105333Z","iopub.status.idle":"2025-02-01T12:47:28.463504Z","shell.execute_reply":"2025-02-01T12:47:28.462498Z"},"papermill":{"duration":1.367835,"end_time":"2025-02-01T12:47:28.465463","exception":false,"start_time":"2025-02-01T12:47:27.097628","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["0                                                         [None, None, None, None, None, None, None, None, None]\n","1                                             [None, None, None, None, None, None, None, None, None, None, None]\n","2                                 [None, None, None, None, None, None, None, None, None, None, None, None, None]\n","3                                                               [None, None, None, None, None, None, None, None]\n","4                                       [None, None, None, None, None, None, None, None, None, None, None, None]\n","                                                           ...                                                  \n","591748                                  [None, None, None, None, None, None, None, None, None, None, None, None]\n","591749                            [None, None, None, None, None, None, None, None, None, None, None, None, None]\n","591750                                              [None, None, None, None, None, None, None, None, None, None]\n","591751    [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n","591752                                                          [None, None, None, None, None, None, None, None]\n","Name: cleaned_caption, Length: 591753, dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["word_list = []\n","df['cleaned_caption'].apply(lambda lis: [word_list.append(word) for word in lis])"]},{"cell_type":"code","execution_count":13,"id":"8ad9cd6a","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:28.481092Z","iopub.status.busy":"2025-02-01T12:47:28.480296Z","iopub.status.idle":"2025-02-01T12:47:28.951149Z","shell.execute_reply":"2025-02-01T12:47:28.950274Z"},"papermill":{"duration":0.480382,"end_time":"2025-02-01T12:47:28.953104","exception":false,"start_time":"2025-02-01T12:47:28.472722","status":"completed"},"tags":[]},"outputs":[],"source":["from collections import Counter\n","word_dict = Counter(word_list)"]},{"cell_type":"code","execution_count":14,"id":"2a4a88b0","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:28.968165Z","iopub.status.busy":"2025-02-01T12:47:28.967404Z","iopub.status.idle":"2025-02-01T12:47:28.97773Z","shell.execute_reply":"2025-02-01T12:47:28.976914Z"},"papermill":{"duration":0.019425,"end_time":"2025-02-01T12:47:28.97933","exception":false,"start_time":"2025-02-01T12:47:28.959905","status":"completed"},"tags":[]},"outputs":[],"source":["min_freq = 5\n","filtered_words = [word for word, freq in word_dict.items() if freq >= min_freq]\n","filtered_words = ['<unk>', '<pad>'] + filtered_words"]},{"cell_type":"code","execution_count":15,"id":"45e053d8","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:28.994623Z","iopub.status.busy":"2025-02-01T12:47:28.993831Z","iopub.status.idle":"2025-02-01T12:47:29.003623Z","shell.execute_reply":"2025-02-01T12:47:29.002777Z"},"papermill":{"duration":0.019234,"end_time":"2025-02-01T12:47:29.005418","exception":false,"start_time":"2025-02-01T12:47:28.986184","status":"completed"},"tags":[]},"outputs":[],"source":["word_to_index = {word: idx for idx, word in enumerate(filtered_words)}\n","index_to_word = {idx: word for idx, word in enumerate(filtered_words)}"]},{"cell_type":"code","execution_count":16,"id":"fd69b5c9","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2025-02-01T12:47:29.021152Z","iopub.status.busy":"2025-02-01T12:47:29.020536Z","iopub.status.idle":"2025-02-01T12:47:30.969264Z","shell.execute_reply":"2025-02-01T12:47:30.96826Z"},"papermill":{"duration":1.958738,"end_time":"2025-02-01T12:47:30.971452","exception":false,"start_time":"2025-02-01T12:47:29.012714","status":"completed"},"tags":[]},"outputs":[],"source":["df['word_token'] = df['cleaned_caption'].apply(lambda lis : [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in lis])"]},{"cell_type":"code","execution_count":17,"id":"0339b584","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:30.987747Z","iopub.status.busy":"2025-02-01T12:47:30.987171Z","iopub.status.idle":"2025-02-01T12:47:30.997998Z","shell.execute_reply":"2025-02-01T12:47:30.997115Z"},"papermill":{"duration":0.020741,"end_time":"2025-02-01T12:47:30.999667","exception":false,"start_time":"2025-02-01T12:47:30.978926","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>caption</th>\n","      <th>cleaned_caption</th>\n","      <th>seq_len</th>\n","      <th>word_token</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg</td>\n","      <td>A bicycle replica with a clock as the front wheel.</td>\n","      <td>[&lt;start&gt;, bicycle, replica, with, clock, as, front, wheel, &lt;end&gt;]</td>\n","      <td>9</td>\n","      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg</td>\n","      <td>A room with blue walls and a white sink and door.</td>\n","      <td>[&lt;start&gt;, room, with, blue, walls, and, white, sink, and, door, &lt;end&gt;]</td>\n","      <td>11</td>\n","      <td>[2, 11, 5, 12, 13, 14, 15, 16, 14, 17, 10]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            image  \\\n","0  ../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg   \n","1  ../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg   \n","\n","                                              caption  \\\n","0  A bicycle replica with a clock as the front wheel.   \n","1   A room with blue walls and a white sink and door.   \n","\n","                                                          cleaned_caption  \\\n","0       [<start>, bicycle, replica, with, clock, as, front, wheel, <end>]   \n","1  [<start>, room, with, blue, walls, and, white, sink, and, door, <end>]   \n","\n","   seq_len                                  word_token  \n","0        9                [2, 3, 4, 5, 6, 7, 8, 9, 10]  \n","1       11  [2, 11, 5, 12, 13, 14, 15, 16, 14, 17, 10]  "]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df.head(2)"]},{"cell_type":"code","execution_count":18,"id":"1c261a72","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:31.015299Z","iopub.status.busy":"2025-02-01T12:47:31.014489Z","iopub.status.idle":"2025-02-01T12:47:31.062776Z","shell.execute_reply":"2025-02-01T12:47:31.061794Z"},"papermill":{"duration":0.057794,"end_time":"2025-02-01T12:47:31.064445","exception":false,"start_time":"2025-02-01T12:47:31.006651","status":"completed"},"tags":[]},"outputs":[],"source":["max_seq_len = max(df['seq_len'])"]},{"cell_type":"code","execution_count":19,"id":"84fc0881","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:31.079707Z","iopub.status.busy":"2025-02-01T12:47:31.079383Z","iopub.status.idle":"2025-02-01T12:47:31.113035Z","shell.execute_reply":"2025-02-01T12:47:31.112001Z"},"papermill":{"duration":0.043503,"end_time":"2025-02-01T12:47:31.114918","exception":false,"start_time":"2025-02-01T12:47:31.071415","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>word_token</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg</td>\n","      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg</td>\n","      <td>[2, 11, 5, 12, 13, 14, 15, 16, 14, 17, 10]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg</td>\n","      <td>[2, 18, 19, 20, 21, 22, 23, 24, 25, 0, 23, 18, 10]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                            image  \\\n","0  ../input/coco-2017-dataset/coco2017/train2017/000000203564.jpg   \n","1  ../input/coco-2017-dataset/coco2017/train2017/000000322141.jpg   \n","2  ../input/coco-2017-dataset/coco2017/train2017/000000016977.jpg   \n","\n","                                           word_token  \n","0                        [2, 3, 4, 5, 6, 7, 8, 9, 10]  \n","1          [2, 11, 5, 12, 13, 14, 15, 16, 14, 17, 10]  \n","2  [2, 18, 19, 20, 21, 22, 23, 24, 25, 0, 23, 18, 10]  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df.drop(columns=['caption', 'cleaned_caption', 'seq_len'], inplace=True)\n","df.head(3)"]},{"cell_type":"code","execution_count":20,"id":"209fcf3c","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:31.129821Z","iopub.status.busy":"2025-02-01T12:47:31.129531Z","iopub.status.idle":"2025-02-01T12:47:31.133376Z","shell.execute_reply":"2025-02-01T12:47:31.132654Z"},"papermill":{"duration":0.013196,"end_time":"2025-02-01T12:47:31.134956","exception":false,"start_time":"2025-02-01T12:47:31.12176","status":"completed"},"tags":[]},"outputs":[],"source":["train_size = int(0.9*len(df))\n","test_size = len(df) - train_size\n","#/kaggle/input/flickr8k/Images"]},{"cell_type":"code","execution_count":21,"id":"cdde9de7","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:31.149639Z","iopub.status.busy":"2025-02-01T12:47:31.149335Z","iopub.status.idle":"2025-02-01T12:47:36.38961Z","shell.execute_reply":"2025-02-01T12:47:36.388908Z"},"papermill":{"duration":5.249983,"end_time":"2025-02-01T12:47:36.391661","exception":false,"start_time":"2025-02-01T12:47:31.141678","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import os\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, img_dir, dataframe):\n","        self.img_dir = img_dir\n","        self.dataframe = dataframe\n","        self.scaler = transforms.Resize([299, 299])\n","        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","        self.to_tensor = transforms.ToTensor()\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.dataframe.iloc[idx, 0]\n","        label = self.dataframe.iloc[idx, 1]\n","        \n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path)\n","        if image.mode == \"L\":\n","            image = image.convert(\"RGB\")\n","        t_img = self.normalize(self.to_tensor(self.scaler(image)))\n","        return t_img, torch.tensor(label)"]},{"cell_type":"code","execution_count":22,"id":"0884d9dd","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.4078Z","iopub.status.busy":"2025-02-01T12:47:36.407364Z","iopub.status.idle":"2025-02-01T12:47:36.411611Z","shell.execute_reply":"2025-02-01T12:47:36.410816Z"},"papermill":{"duration":0.014197,"end_time":"2025-02-01T12:47:36.413365","exception":false,"start_time":"2025-02-01T12:47:36.399168","status":"completed"},"tags":[]},"outputs":[],"source":["img_dir = '/kaggle/input/'\n","dataset = ImageDataset(img_dir, df)"]},{"cell_type":"code","execution_count":23,"id":"2d8bc715","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.428663Z","iopub.status.busy":"2025-02-01T12:47:36.428338Z","iopub.status.idle":"2025-02-01T12:47:36.43281Z","shell.execute_reply":"2025-02-01T12:47:36.432Z"},"papermill":{"duration":0.014273,"end_time":"2025-02-01T12:47:36.434595","exception":false,"start_time":"2025-02-01T12:47:36.420322","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 256\n","vocab_size = len(word_dict)\n","d_model = 256\n","nhead = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","dim_feedforward = 2048\n","learning_rate = 0.001\n","dropout = 0.5"]},{"cell_type":"code","execution_count":24,"id":"4b714c32","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.449631Z","iopub.status.busy":"2025-02-01T12:47:36.449334Z","iopub.status.idle":"2025-02-01T12:47:36.523778Z","shell.execute_reply":"2025-02-01T12:47:36.522996Z"},"papermill":{"duration":0.084215,"end_time":"2025-02-01T12:47:36.525843","exception":false,"start_time":"2025-02-01T12:47:36.441628","status":"completed"},"tags":[]},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_fn(batch):\n","    \"\"\"\n","    Custom collate function for dynamic padding.\n","    batch: A list of tuples (image, caption).\n","    \"\"\"\n","    images, captions = zip(*batch)\n","    \n","    # Pad captions to the maximum length in the batch\n","    captions = [torch.tensor(caption) for caption in captions]\n","    captions = pad_sequence(captions, batch_first=True, padding_value=word_to_index['<pad>'])  # 0 is the index for <pad>\n","    \n","    # Stack images into a single tensor\n","    images = torch.stack(images, dim=0)\n","    \n","    return images, captions\n","\n","# Create DataLoader with dynamic padding\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)"]},{"cell_type":"code","execution_count":25,"id":"00533b38","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.542348Z","iopub.status.busy":"2025-02-01T12:47:36.541504Z","iopub.status.idle":"2025-02-01T12:47:36.560199Z","shell.execute_reply":"2025-02-01T12:47:36.559259Z"},"papermill":{"duration":0.02856,"end_time":"2025-02-01T12:47:36.561909","exception":false,"start_time":"2025-02-01T12:47:36.533349","status":"completed"},"tags":[]},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","\n","class ImageCaptioningModel(nn.Module):\n","    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n","        super(ImageCaptioningModel, self).__init__()\n","        self.inception = models.inception_v3(pretrained=True)\n","        \n","        for param in self.inception.parameters():\n","            param.requires_grad = False\n","            \n","        self.inception.fc = nn.Linear(self.inception.fc.in_features, d_model)\n","        self.embedding = nn.Embedding(vocab_size, d_model)\n","        self.positional_encoding = nn.Parameter(torch.zeros(1, max_seq_len, d_model))\n","        self.transformer = nn.Transformer(d_model=d_model,\n","                                          nhead=nhead,\n","                                          num_encoder_layers=num_encoder_layers,\n","                                          num_decoder_layers=num_decoder_layers,\n","                                          dim_feedforward=dim_feedforward,\n","                                          dropout=dropout,\n","                                          batch_first=True)\n","        self.fc_out = nn.Linear(d_model, vocab_size)\n","        \n","        for param in self.inception.fc.parameters():\n","            param.requires_grad = True\n","            \n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, image, caption): \n","        # print(image.size())\n","        features = self.inception(image)\n","\n","        if isinstance(features, tuple):\n","            features = features[0]\n","\n","        features = self.dropout(self.relu(features))\n","        features = features.unsqueeze(1)\n","\n","        caption_embedding = self.embedding(caption)\n","        caption_embedding = self.dropout(caption_embedding)\n","        # caption_embedding = caption_embedding.permute(1, 0, 2)\n","        # print(caption_embedding.size())\n","        caption_len = caption_embedding.size(1)\n","        caption_embedding = caption_embedding + self.positional_encoding[:, :caption_len, :]\n","\n","        tgt_mask = self.generate_square_subsequent_mask(caption_len).to(device)\n","        # print(f'features dim = {features.size()}')\n","        # print(f'caption embedding dim = {caption_embedding.size()}')\n","        output = self.transformer(src=features, tgt=caption_embedding, tgt_mask=tgt_mask)\n","\n","        output = self.fc_out(output)\n","        output = output.permute(1, 0, 2)\n","        return output\n","\n","    def generate_square_subsequent_mask(self, sz):\n","        \"\"\"Generate a causal mask to prevent the decoder from attending to future tokens.\"\"\"\n","        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask"]},{"cell_type":"code","execution_count":26,"id":"f9019233","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.577199Z","iopub.status.busy":"2025-02-01T12:47:36.576865Z","iopub.status.idle":"2025-02-01T12:47:36.580825Z","shell.execute_reply":"2025-02-01T12:47:36.580022Z"},"papermill":{"duration":0.013564,"end_time":"2025-02-01T12:47:36.582607","exception":false,"start_time":"2025-02-01T12:47:36.569043","status":"completed"},"tags":[]},"outputs":[],"source":["# class LSTMCaptionGenerator(nn.Module):\n","#     def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n","#         super(LSTMCaptionGenerator, self).__init__()\n","#         self.embed = nn.Embedding(vocab_size, embed_size)\n","#         self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n","#         self.linear = nn.Linear(hidden_size, vocab_size)\n","#         self.dropout = nn.Dropout(0.5)\n","    \n","#     def forward(self, features, captions):\n","#         embeddings = self.embed(captions)\n","#         embeddings = self.dropout(embeddings)\n","#         # print(f\"dim of features after unsqueezzing = \", features.unsqueeze(1).size())\n","#         # print(f\"dim of embeddings = \", embeddings.size())\n","#         # repeated_features = features.unsqueeze(1).repeat(1, embeddings.size(1), 1)\n","#         print(features.size())\n","#         print(embeddings.size())\n","#         embeddings = torch.cat((features.unsqueeze(1), embeddings[:, :-1, :]), dim=1)\n","#         # embeddings = torch.cat((repeated_features, embeddings), dim=1) \n","#         # print(f\"embedding dim={embeddings.size()}\")\n","#         hiddens, _ = self.lstm(embeddings)\n","#         outputs = self.linear(hiddens)\n","#         return outputs"]},{"cell_type":"code","execution_count":27,"id":"ac85f06b","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.597849Z","iopub.status.busy":"2025-02-01T12:47:36.597551Z","iopub.status.idle":"2025-02-01T12:47:36.601504Z","shell.execute_reply":"2025-02-01T12:47:36.60067Z"},"papermill":{"duration":0.013768,"end_time":"2025-02-01T12:47:36.603387","exception":false,"start_time":"2025-02-01T12:47:36.589619","status":"completed"},"tags":[]},"outputs":[],"source":["# class CNN_LSTM_model(nn.Module):  # Must inherit from nn.Module\n","#     def __init__(self, vocab_size, embed_size, hidden_size, num_layers, max_seq_length):\n","#         super(CNN_LSTM_model, self).__init__()\n","#         self.CNN_model = CNNFeatureExtractor()  # Initialize CNN feature extractor\n","#         self.LSTM_model = LSTMCaptionGenerator(vocab_size, embed_size, hidden_size, num_layers, max_seq_length)  # Initialize LSTM model\n","\n","#     def forward(self, image, captions):\n","#         features = self.CNN_model(image)  # Get image features from CNN\n","#         outputs = self.LSTM_model(features, captions)  # Use image features and captions in LSTM\n","#         return outputs"]},{"cell_type":"code","execution_count":28,"id":"cd922fce","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:36.619005Z","iopub.status.busy":"2025-02-01T12:47:36.618267Z","iopub.status.idle":"2025-02-01T12:47:38.338894Z","shell.execute_reply":"2025-02-01T12:47:38.338111Z"},"papermill":{"duration":1.730801,"end_time":"2025-02-01T12:47:38.341045","exception":false,"start_time":"2025-02-01T12:47:36.610244","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n","100%|██████████| 104M/104M [00:00<00:00, 198MB/s] \n"]}],"source":["import torch\n","\n","device = \"\"\n","if torch.cuda.is_available():\n","    device = 'cuda'\n","else:\n","    device = 'cpu'\n","\n","model = ImageCaptioningModel(d_model=d_model,\n","                             nhead=nhead,\n","                             num_encoder_layers=num_encoder_layers,\n","                             num_decoder_layers=num_decoder_layers,\n","                             dim_feedforward=dim_feedforward,\n","                             dropout=dropout).to(device)"]},{"cell_type":"code","execution_count":29,"id":"610d60e8","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:38.358672Z","iopub.status.busy":"2025-02-01T12:47:38.35834Z","iopub.status.idle":"2025-02-01T12:47:38.364089Z","shell.execute_reply":"2025-02-01T12:47:38.363234Z"},"papermill":{"duration":0.016352,"end_time":"2025-02-01T12:47:38.365782","exception":false,"start_time":"2025-02-01T12:47:38.34943","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["'<unk>'"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["index_to_word[0]"]},{"cell_type":"code","execution_count":30,"id":"5348548c","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:38.383343Z","iopub.status.busy":"2025-02-01T12:47:38.382967Z","iopub.status.idle":"2025-02-01T12:47:39.990363Z","shell.execute_reply":"2025-02-01T12:47:39.989436Z"},"papermill":{"duration":1.618766,"end_time":"2025-02-01T12:47:39.992551","exception":false,"start_time":"2025-02-01T12:47:38.373785","status":"completed"},"tags":[]},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","def calculate_bleu_score(predictions, references, idx2word, tokenizer):\n","    \"\"\"\n","    Calculate BLEU score for a batch of predictions vs references.\n","    predictions: List of predicted captions (list of words).\n","    references: List of ground truth captions (list of words).\n","    \"\"\"\n","    # Convert predicted captions and ground truth into the format required by BLEU\n","    # References should be a list of lists, and predictions should be a list of sentences.\n","    bleu_score = corpus_bleu(references, predictions)\n","    return bleu_score"]},{"cell_type":"code","execution_count":31,"id":"0999b1c1","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:40.00972Z","iopub.status.busy":"2025-02-01T12:47:40.00925Z","iopub.status.idle":"2025-02-01T12:47:40.018721Z","shell.execute_reply":"2025-02-01T12:47:40.017813Z"},"papermill":{"duration":0.019874,"end_time":"2025-02-01T12:47:40.020527","exception":false,"start_time":"2025-02-01T12:47:40.000653","status":"completed"},"tags":[]},"outputs":[],"source":["from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import nltk\n","import torch.nn.utils as utils\n","\n","def train_and_test(num_epochs):\n","    # Initialize optimizer and loss function\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","    criterion = nn.CrossEntropyLoss(ignore_index=word_to_index['<pad>'])\n","\n","    for epoch in range(num_epochs):\n","        # Training phase\n","        model.train()\n","        total_loss_train = 0\n","        for image, caption in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Training\"):\n","            image = image.to(device)\n","            caption = caption.to(device)\n","\n","            # print(image.size())\n","\n","            optimizer.zero_grad()\n","            predicted_caption = model(image, caption)\n","            predicted_caption = predicted_caption.reshape(-1, predicted_caption.size(-1))\n","            caption = caption.reshape(-1)\n","\n","            loss = criterion(predicted_caption, caption)\n","            loss.backward()\n","            utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","            scheduler.step()\n","            total_loss_train += loss.item()\n","\n","        print(f\"Train Loss at epoch {epoch+1} = {total_loss_train / len(train_loader)}\")\n","\n","        # Testing phase\n","        model.eval()\n","        total_loss_test = 0\n","\n","        for image, caption in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} Testing\"):\n","            image = image.to(device)\n","            caption = caption.to(device)\n","\n","            predicted_caption = model(image, caption)\n","            predicted_caption = predicted_caption.reshape(-1, predicted_caption.size(-1))\n","            caption = caption.reshape(-1)\n","            # Calculate loss for test\n","            loss = criterion(predicted_caption, caption)\n","            total_loss_test += loss.item()\n","\n","        print(f\"Test Loss at epoch {epoch+1} = {total_loss_test / len(test_loader)}\")\n"]},{"cell_type":"code","execution_count":32,"id":"3a99dc09","metadata":{"execution":{"iopub.execute_input":"2025-02-01T12:47:40.037251Z","iopub.status.busy":"2025-02-01T12:47:40.036873Z","iopub.status.idle":"2025-02-01T21:10:51.127393Z","shell.execute_reply":"2025-02-01T21:10:51.126311Z"},"papermill":{"duration":30191.10142,"end_time":"2025-02-01T21:10:51.129675","exception":false,"start_time":"2025-02-01T12:47:40.028255","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 1/10 Training: 100%|██████████| 2081/2081 [44:40<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 1 = 6.90045301505203\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 1/10 Testing: 100%|██████████| 232/232 [04:55<00:00,  1.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 1 = 6.395128866721844\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 2/10 Training: 100%|██████████| 2081/2081 [44:06<00:00,  1.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 2 = 6.890484163475861\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 2/10 Testing: 100%|██████████| 232/232 [04:58<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 2 = 6.395128529647301\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 3/10 Training: 100%|██████████| 2081/2081 [45:28<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 3 = 6.8900830435214395\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 3/10 Testing: 100%|██████████| 232/232 [04:55<00:00,  1.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 3 = 6.395128652967256\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 4/10 Training: 100%|██████████| 2081/2081 [45:34<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 4 = 6.8901147015217346\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 4/10 Testing: 100%|██████████| 232/232 [05:05<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 4 = 6.395128685852577\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 5/10 Training: 100%|██████████| 2081/2081 [45:55<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 5 = 6.890206906384198\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 5/10 Testing: 100%|██████████| 232/232 [05:00<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 5 = 6.39512836111003\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 6/10 Training: 100%|██████████| 2081/2081 [45:05<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 6 = 6.890297953409967\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 6/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 6/10 Testing: 100%|██████████| 232/232 [05:03<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 6 = 6.395128320003378\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 7/10 Training: 100%|██████████| 2081/2081 [45:24<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 7 = 6.890450845367344\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 7/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 7/10 Testing: 100%|██████████| 232/232 [05:07<00:00,  1.33s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 7 = 6.395128365220694\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 8/10 Training: 100%|██████████| 2081/2081 [46:21<00:00,  1.34s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 8 = 6.890212860776506\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 8/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 8/10 Testing: 100%|██████████| 232/232 [05:05<00:00,  1.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 8 = 6.39512824190074\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 9/10 Training: 100%|██████████| 2081/2081 [45:25<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 9 = 6.890257402087335\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 9/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 9/10 Testing: 100%|██████████| 232/232 [04:56<00:00,  1.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 9 = 6.395128766010547\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/10 Training:   0%|          | 0/2081 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 10/10 Training: 100%|██████████| 2081/2081 [45:03<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss at epoch 10 = 6.890125500359597\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 10/10 Testing:   0%|          | 0/232 [00:00<?, ?it/s]/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","/tmp/ipykernel_23/2599963553.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  captions = [torch.tensor(caption) for caption in captions]\n","Epoch 10/10 Testing: 100%|██████████| 232/232 [04:55<00:00,  1.27s/it]"]},{"name":"stdout","output_type":"stream","text":["Test Loss at epoch 10 = 6.395128733125226\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["train_and_test(10)"]},{"cell_type":"code","execution_count":33,"id":"ab91d8d6","metadata":{"execution":{"iopub.execute_input":"2025-02-01T21:10:53.372555Z","iopub.status.busy":"2025-02-01T21:10:53.372216Z","iopub.status.idle":"2025-02-01T21:10:53.793446Z","shell.execute_reply":"2025-02-01T21:10:53.792645Z"},"papermill":{"duration":1.574485,"end_time":"2025-02-01T21:10:53.79533","exception":false,"start_time":"2025-02-01T21:10:52.220845","status":"completed"},"tags":[]},"outputs":[],"source":["torch.save(model, \"model_transformer_10_epochs.pth\")"]},{"cell_type":"code","execution_count":34,"id":"5bb3410c","metadata":{"execution":{"iopub.execute_input":"2025-02-01T21:10:56.083801Z","iopub.status.busy":"2025-02-01T21:10:56.083432Z","iopub.status.idle":"2025-02-01T21:10:56.08715Z","shell.execute_reply":"2025-02-01T21:10:56.086341Z"},"papermill":{"duration":1.138123,"end_time":"2025-02-01T21:10:56.08882","exception":false,"start_time":"2025-02-01T21:10:54.950697","status":"completed"},"tags":[]},"outputs":[],"source":["# encoder = torch.load(\"/kaggle/input/image-captioning_coco_10-epochs/pytorch/default/1/encoder_10_epochs.pth\")\n","# decoder = torch.load(\"/kaggle/input/image-captioning_coco_10-epochs/pytorch/default/1/decoder_10_epochs.pth\")"]},{"cell_type":"code","execution_count":35,"id":"ec7d8260","metadata":{"execution":{"iopub.execute_input":"2025-02-01T21:10:58.426765Z","iopub.status.busy":"2025-02-01T21:10:58.42643Z","iopub.status.idle":"2025-02-01T21:10:58.432131Z","shell.execute_reply":"2025-02-01T21:10:58.431374Z"},"papermill":{"duration":1.210672,"end_time":"2025-02-01T21:10:58.4338","exception":false,"start_time":"2025-02-01T21:10:57.223128","status":"completed"},"tags":[]},"outputs":[],"source":["def load_img(idx):\n","    \n","    scaler = transforms.Resize([299, 299])\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    to_tensor = transforms.ToTensor()\n","    \n","    img_name = df.iloc[idx, 0]\n","    label = df.iloc[idx, 1]\n","        \n","    img_path = os.path.join(img_dir, img_name)\n","    image = Image.open(img_path)\n","    t_img = normalize(to_tensor(scaler(image)))\n","    # t_img = torch.tensor(t_img)\n","    # label = torch.tensor(label)\n","    return t_img, label"]},{"cell_type":"code","execution_count":36,"id":"85b803dd","metadata":{"execution":{"iopub.execute_input":"2025-02-01T21:11:00.634135Z","iopub.status.busy":"2025-02-01T21:11:00.63378Z","iopub.status.idle":"2025-02-01T21:11:00.643589Z","shell.execute_reply":"2025-02-01T21:11:00.642759Z"},"papermill":{"duration":1.143886,"end_time":"2025-02-01T21:11:00.6451","exception":false,"start_time":"2025-02-01T21:10:59.501214","status":"completed"},"tags":[]},"outputs":[],"source":["def inference(image, beam_width=5, max_seq_len=48):\n","    model.eval()\n","    start_token = torch.tensor([[1]]).to(device)  # Start token\n","    image = image.to(device)\n","\n","    with torch.no_grad():\n","        # Get image features\n","        features = model.inception(image)\n","        if isinstance(features, tuple):\n","            features = features[0]\n","        features = model.dropout(model.relu(features))\n","        features = features.unsqueeze(1)  # Add sequence dimension\n","\n","        # Initialize beam search\n","        sequences = [[start_token, 0.0]]  # List of [sequence, score]\n","\n","        for _ in range(max_seq_len - 1):\n","            all_candidates = []\n","            for seq, score in sequences:\n","                if seq[0, -1].item() == 2:  # Stop if END token is generated\n","                    all_candidates.append([seq, score])\n","                    continue\n","\n","                # Generate next tokens\n","                caption_embedding = model.embedding(seq)\n","                caption_embedding = model.dropout(caption_embedding)\n","                pos_encoding = model.positional_encoding[:, :caption_embedding.size(1), :]\n","                caption_embedding = caption_embedding + pos_encoding\n","\n","                tgt_mask = model.generate_square_subsequent_mask(seq.size(1)).to(device)\n","                output = model.transformer(src=features, tgt=caption_embedding, tgt_mask=tgt_mask)\n","                output = model.fc_out(output)\n","\n","                # Get top-k predictions\n","                log_probs = torch.log_softmax(output[:, -1, :], dim=-1)\n","                top_k_scores, top_k_tokens = log_probs.topk(beam_width, dim=-1)\n","\n","                for i in range(beam_width):\n","                    candidate_seq = torch.cat([seq, top_k_tokens[0, i].unsqueeze(0).unsqueeze(0)], dim=1)\n","                    candidate_score = score + top_k_scores[0, i].item()\n","                    all_candidates.append([candidate_seq, candidate_score])\n","\n","            # Select top-k candidates\n","            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n","\n","        # Select the best sequence\n","        best_sequence = sequences[0][0]\n","        result_caption = [token.item() for token in best_sequence[0]]\n","\n","    # Convert indices to words\n","    caption = [index_to_word[idx] for idx in result_caption]\n","    return caption"]},{"cell_type":"code","execution_count":37,"id":"cef3ab49","metadata":{"execution":{"iopub.execute_input":"2025-02-01T21:11:02.909591Z","iopub.status.busy":"2025-02-01T21:11:02.909177Z","iopub.status.idle":"2025-02-01T21:11:03.117758Z","shell.execute_reply":"2025-02-01T21:11:03.116806Z"},"papermill":{"duration":1.344102,"end_time":"2025-02-01T21:11:03.119568","exception":false,"start_time":"2025-02-01T21:11:01.775466","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["['<pad>', '<start>']\n","['<start>', 'gang', 'of', 'bikers', 'sitting', 'on', 'top', 'of', 'motorcycles', 'on', 'sidewalk', '<end>']\n"]}],"source":["img, caption = load_img(500)\n","# print(img.size())\n","img = img.unsqueeze(0)\n","# print(img.size())\n","res = inference(img)\n","expected = [index_to_word[idx] for idx in caption]\n","print(res)\n","print(expected) "]},{"cell_type":"code","execution_count":null,"id":"3db9d304","metadata":{"papermill":{"duration":1.205294,"end_time":"2025-02-01T21:11:05.47858","exception":false,"start_time":"2025-02-01T21:11:04.273286","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":857191,"sourceId":1462296,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":30233.903558,"end_time":"2025-02-01T21:11:09.260431","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-01T12:47:15.356873","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}